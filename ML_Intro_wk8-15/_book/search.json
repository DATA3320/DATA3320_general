[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ML_Intro_Q_source",
    "section": "",
    "text": "This is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "workbooks/001_Setup.html",
    "href": "workbooks/001_Setup.html",
    "title": "1  Tools and Setup",
    "section": "",
    "text": "In data science we generally work with a common set of tools and software packages. We’ll work to get a few of the basic ones setup now. All of what we’ll touch on now will come up repeatedly as we go through the course."
  },
  {
    "objectID": "workbooks/001_Setup.html#anaconda",
    "href": "workbooks/001_Setup.html#anaconda",
    "title": "1  Tools and Setup",
    "section": "1.1 Anaconda",
    "text": "1.1 Anaconda\nAnaconda, the program that you downloaded and installed to get to this point, is a big package of a bunch of useful data science programs and packages. It installs a bunch of this stuff, and more, all at once, so we don’t need to hunt around downloading and installing all kinds of stuff - installing Anaconda gives us all a (near) identical starting point.\nEvery time we use some function that someone else has developed, which is constantly, we need to have that package installed first. Anaconda is a jump start on adding all of that stuff. We’ll look at how to install more stuff later on. In the example below we are importing a package called “platform”, and using that to tell us which version of Python we’re using.\nNote: you may have more than one version of Python installed (other programs may have installed it), this is fine. We do need to be a little attentive if that is the case, as when we install things we want them to be installed into the “correct” one.\n\n\n3.9.7"
  },
  {
    "objectID": "workbooks/001_Setup.html#python-vs-code-jupyter-notebooks",
    "href": "workbooks/001_Setup.html#python-vs-code-jupyter-notebooks",
    "title": "1  Tools and Setup",
    "section": "1.2 Python, VS Code, Jupyter Notebooks",
    "text": "1.2 Python, VS Code, Jupyter Notebooks\nThe first 3 of the tools that we will be using are:\n\n\nPython - python is the programming language we’ll use to do our work. Python is the most common language used in data science and is one of the more common programming languages in the world. For us there are a few key benefits:\n\n\nPython is relatively easy to learn and use. Compared to other languages, it is very approachable.\n\nPython is commonly used in data science applications. So we can import things that others have written and find examples and documentation online.\n\nPython is very commonly used in industry, so the skills we learn here are very transferable to real work.\n\n\nVS Code - VS Code is a tool called an IDE - an integrated development environment - basically a text editor used to write programs. We will use VSCode to create, edit, and run what we make.\n\nJupyter Notebooks - this one is behind the scenes. This file, and the others that we’ll create and use, are called notebook files. These files are special because we can write code, run code, and add webpage like text and images all on one page. This makes it easy for us to do everything in one place. In practice, it is common to develop things in a notebook like we’ll be doing, then export the final product to be used in a production environment.\n\nThese 3 tools are the building blocks of everything that we’ll do.\n\n1.2.1 Notebooks\nAs mentioned above, notebook files like this one are the main type of file we’ll use. In a notebook we can write code, run it, see the results, and embed that all in a web page style document.\nNotebooks have a few key features that we should be explore right up front:\n\n\nCells - the content of a notebook is all in cells; there are two types of cells - markup and code.\n\n\nMarkup - markup cells are like this one, fancy text boxes. Each is basically a mini-webpage. We can put text, instructions, or explainations in markup cells.\n\nCode - code cells are where the actual program code goes. Code cells can be run, and will output their results below the cell. See a code cell below this one.\n\n\nOutput - the output of whatever we are doing will display directly below the cell that we run.\n\nOur end result will be something like a web page that can be filled with explainations and information, along with pieces of code that generate the results. The one stop shop of programming.\n\n1.2.1.1 Example - Simple Python Code\nTo the left of the cell below, a little play button should appear when you mouse over that cell. Click the play button to run (execute the code) in the cell and see the results printed below.\n\n\nI am a code cell!!\n3 times 4 is 12\n\n\n\n\n\n1.2.2 VS Code\nVS Code is a full featured program to develop other programs, there are a lot of features and capabilities of which we only need a few.\nThe good thing about VS Code is that it incorporates almost everything we need into one centralized program. We can write code, run it, manage files, and sync to a repository all from this one window.\nVS Code consolodates several pieces of functionality into one tool:\n\n\nAt it’s core, it is an IDE (Integrated Development Environment), or basically a text editor for computer programming.\n\nVS Code also includes an “environment” in which we can execute our programs (these notebook pages).\n\nIt also integrates with GitHub (repository for computer code), for saving and sharing code.\n\nThis means that we can write, run, save, and share our work all from one tool, which helps us keep things relatively simple. One key thing to note is that nothing we do “belongs” to VS Code - we can write and execute this code anywhere, we’ve just chosen this as our tool. Just like you can create a document in Word, Google Documents, or whatever Apple gives you with a Mac. The contents of your document can be created in any of the tools, shared between them, and “executed” (read by someone) in the same way no matter how it was made.\n\n1.2.2.1 Example - Load Some Data\nLoading a dataset is a very common first-ish step for our work. Here we’ll load a CSV file, which is most common, but we can also load different types of files or connect to data in a database or over the internet.\nWe’ll also load a package called Pandas to help us (computer scientists are not known for excellent naming practices). The head(x) command gives us a preview of the first ‘x’ rows of our data; when the x is missing, the default is 5. This type of optional/default setup for arguments is common.\n\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Name\n      Sex\n      Age\n      SibSp\n      Parch\n      Ticket\n      Fare\n      Cabin\n      Embarked\n    \n  \n  \n    \n      0\n      1\n      0\n      3\n      Braund, Mr. Owen Harris\n      male\n      22.0\n      1\n      0\n      A/5 21171\n      7.2500\n      NaN\n      S\n    \n    \n      1\n      2\n      1\n      1\n      Cumings, Mrs. John Bradley (Florence Briggs Th...\n      female\n      38.0\n      1\n      0\n      PC 17599\n      71.2833\n      C85\n      C\n    \n    \n      2\n      3\n      1\n      3\n      Heikkinen, Miss. Laina\n      female\n      26.0\n      0\n      0\n      STON/O2. 3101282\n      7.9250\n      NaN\n      S\n    \n    \n      3\n      4\n      1\n      1\n      Futrelle, Mrs. Jacques Heath (Lily May Peel)\n      female\n      35.0\n      1\n      0\n      113803\n      53.1000\n      C123\n      S\n    \n    \n      4\n      5\n      0\n      3\n      Allen, Mr. William Henry\n      male\n      35.0\n      0\n      0\n      373450\n      8.0500\n      NaN\n      S\n    \n  \n\n\n\n\n\n\n1.2.2.2 VS Code Live Share and Pair Programming\nOne other cool thing that VS Code allows us to do is a live sharing session of the code window. This will allow me to post a link for a class session from my VS Code install on my computer. You can take that link, load it in VS Code, and you will get whatever I’m doing updated live in your VS Code window. It is kind of like a screen share, but just for the code file, so you can still configure and resize the VS Code window as you please, and only the code inside of it will update.\nThis requires a little bit of setup to use, but is easy:\n\n\nInstall Live Share and Live Share Extension Pack extensions by clicking on the Extensions icon (4 blocks with one “flying away”) in the toolbar on the left, searching for the two extensions, and clicking install.\n\nA new Live Share icon (a circle with an arrow over it) on the left. To join a session take the link I post, click “Join”, and enter the link.\n\nYou can also use this to work together with others. “Pair Programing”, or working side-by-side with someone to talk through issues when you are coding is a very common practice, and it can really help when dealing with something compex or confusing. You can click the “Share” link and generate a link that you can share with team members or friends - feel free to do so if we have a spot in class where we break for you all to work on an exercise. As well, if you’re working on a project with others or grinding through some practice problems, this can be very useful.\nThere is a lot of documentation online, one explainer with a video is located here: https://code.visualstudio.com/learn/collaboration/live-share The Live Share window also has a link to the full documentation.\n\n\n\n1.2.3 Python and Environments\nOur code will be written in a programming language called Python; all of the code cells on this page are examples of Python code.\nIn addition to being a programming language, Python also comes with environments. An environment is the “universe” inside of which each Python program runs. We can have several, and you may have some different ones on your computer that came with other programs you may have installed.\nThere is a little icon in the top right of the notebook that indicates which environment (a.k.a kernel) you are currently using. By default, Anaconda sets one up named “base” that has a bunch of useful default stuff in it. We generally want to use this one. Each of the libraries (things such as pandas) that we install will only “exist” in one environment - the one in which they were installed. As we go through the semester we’ll add other libraries to do other stuff, if we try to run our code in an environment where that stuff doesn’t exist, we’ll get an error, since it can’t find it.\nThis part is very important to people who are producing programs that are going to be distributed to others (since they can rely on all the stuff they need existing in that environment), it is mostly just a minor annoyance to us, since we don’t need to setup multiple different environments.\n\n1.2.3.1 Python vs Notebooks\nWe will do all of our work in Python in these notebook files. This is very common for data science work as we can make our programs and see the results all in one page. In “real” production environments we would probably still use notebooks just like ours to do the development, then export part (either a trained model or portion of code) into another format, which would then be integrated into the actual working systems. We are working entirely on that preparation part, so the last deployment step doesn’t really matter to us.\nIf you’ve ever programmed before you may have seen “regular” python programming in regular, non-notebook files, likely with a .py file extension. Those are created using the same Python language, but are intended to be run like a “normal” program (i.e. someone presses “Run” and the program goes) rather than in the interactive environment we are using here. The language is the same in those files and the code we write, outside of a handfull of commands that are special to either environment; if we want an example of something and we find it in a “regular” python file, that’s still useful because it is almost certainly the same in our notebooks.\n\n\n1.2.3.2 Example - Information on our Dataset\nWe can use some simple commands to get some information about our data.\n\n\nThe describe() command gives us basic statistics (we’ll cover these more soon). The include=“all” part tells it to include things that aren’t numbers.\n\nThe info() command gives us some info on the types of data we have.\n\n\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Name\n      Sex\n      Age\n      SibSp\n      Parch\n      Ticket\n      Fare\n      Cabin\n      Embarked\n    \n  \n  \n    \n      count\n      891.000000\n      891.000000\n      891.000000\n      891\n      891\n      714.000000\n      891.000000\n      891.000000\n      891\n      891.000000\n      204\n      889\n    \n    \n      unique\n      NaN\n      NaN\n      NaN\n      891\n      2\n      NaN\n      NaN\n      NaN\n      681\n      NaN\n      147\n      3\n    \n    \n      top\n      NaN\n      NaN\n      NaN\n      Braund, Mr. Owen Harris\n      male\n      NaN\n      NaN\n      NaN\n      347082\n      NaN\n      B96 B98\n      S\n    \n    \n      freq\n      NaN\n      NaN\n      NaN\n      1\n      577\n      NaN\n      NaN\n      NaN\n      7\n      NaN\n      4\n      644\n    \n    \n      mean\n      446.000000\n      0.383838\n      2.308642\n      NaN\n      NaN\n      29.699118\n      0.523008\n      0.381594\n      NaN\n      32.204208\n      NaN\n      NaN\n    \n    \n      std\n      257.353842\n      0.486592\n      0.836071\n      NaN\n      NaN\n      14.526497\n      1.102743\n      0.806057\n      NaN\n      49.693429\n      NaN\n      NaN\n    \n    \n      min\n      1.000000\n      0.000000\n      1.000000\n      NaN\n      NaN\n      0.420000\n      0.000000\n      0.000000\n      NaN\n      0.000000\n      NaN\n      NaN\n    \n    \n      25%\n      223.500000\n      0.000000\n      2.000000\n      NaN\n      NaN\n      20.125000\n      0.000000\n      0.000000\n      NaN\n      7.910400\n      NaN\n      NaN\n    \n    \n      50%\n      446.000000\n      0.000000\n      3.000000\n      NaN\n      NaN\n      28.000000\n      0.000000\n      0.000000\n      NaN\n      14.454200\n      NaN\n      NaN\n    \n    \n      75%\n      668.500000\n      1.000000\n      3.000000\n      NaN\n      NaN\n      38.000000\n      1.000000\n      0.000000\n      NaN\n      31.000000\n      NaN\n      NaN\n    \n    \n      max\n      891.000000\n      1.000000\n      3.000000\n      NaN\n      NaN\n      80.000000\n      8.000000\n      6.000000\n      NaN\n      512.329200\n      NaN\n      NaN\n    \n  \n\n\n\n\n\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n\n\n\n\n\n1.2.4 Saving and Comitting\nIf we look at the toolbar on the left of VS Code, we’ll usually see some little blue balls with numbers in them as we work. These bubbles indicate our pending changes, and they are important for us when we are saving or uploading our work.\nIf there is a bubble on the top (Explorer) icon of the toolbar, that is an indication that you have changes to your files that are not yet saved. The number is the number of files that have been modified. Use the Save or Save All command to save them.\nIf there is a bubble on the thrid (Source Control) icon of the toolbar, that is an indication that you have saved changes that have not been “pushed” (uploaded) to the central repository on GitHub."
  },
  {
    "objectID": "workbooks/001_Setup.html#git-and-github",
    "href": "workbooks/001_Setup.html#git-and-github",
    "title": "1  Tools and Setup",
    "section": "1.3 Git and GitHub",
    "text": "1.3 Git and GitHub\nAnother of our foundational tools is GitHub, and its component Git. Git and GitHub are tools that help us manage and store code, share it between multiple contributors, update versions, and package final products. It is effectively a file manager for programs being developed.\nNote: At some point in setting up VS Code you’ll need to install Git (without the hub) for this part to start working. In the window on the left, there will be a link to “Git” at some point, click that and follow the directions. This part may differ depending on what you’ve installed on your machine before and if you’re on a Windows or Mac, there may be instructions to install some other program along the way, just follow those directions.\nLike the other tools GitHub has a lot of capabilites, and we only need the basics. We’ll use GitHub to:\n\n\nShare content with you, like this repository. I can give you the Github link for you to clone the repository, you then get a copy of the entire set of files.\n\nUpdate changes. As we go through the semester I can update the files in this repository, and you can use the “Pull” command to automatically get all my changes.\n\nManage your work. You can save your work to your own GitHub repository and it will do things like track changes and versions for you.\n\nShare with others. When there is more than one person working on a project, GitHub will manage changes made by different people to ensure that things stay in sync.\n\nIn more elaborate setups you can also use GitHub to do things like take in bug reports or run automated testing routines.\n\nGitHub is a very, very commonly used tool in industry. It can be a little bit of a headache initially, but it is definitely worth the hassle of learning how to use it. If you work in any programming related job there is a very high likelihood you’ll use Git, or an alternative that does the same thing.\n\n1.3.1 Important Actions\nThere are a few fundamental things we need to know and be comfortable with to use GitHub and be successful:\n\n\nCloning a repository - you’ve all done this to get here, cloning a repository makes a copy of a code repository on GitHub and saves it to your computer. You can then work on it, and if you were in a real job you’d have other people working on the same repository at the same time. For assignments, you’ll clone the repository I post that has your starting point in it, then start work on your copy.\n\nCommitting your changes - as you work on things like projects and assignments you can submit your progress into your own GitHub repository. Each time you submit changes GitHub will do a lot of work to maintain your code - versions will be archived, so you can roll back changes; if you are working with others, your changes will be merged; if your computer goes up in flames everything is saved online.\n\n\n1.3.1.1 Using GitHub\nThere are lots of things that we can do in GitHub, but we’ll mostly stick to relatively simple actions:\n\n\nCloning a repository - you’ve all done this to get here. Take the link, go to the Source Control window, click Clone Repository, enter the link, and choose where to save it on your computer. When you do assignments you’ll do this to download a repository that is your starting point.\n\nPull - update FROM the online repository TO your computer. As I make updates to these workbooks throughout the term, you’ll regularly (before every class usually) perform a pull, or grab any changes and update your machine. In the source control window, click the 3 dot icon in the header and choose Pull in the menu.\n\nCommit - push FROM your computer TO the online repository. As you work on an assignment, you’ll want to regularly commit as you progress. Each time you do, that version will be logged on the server and backed up. In the source control window, click the check mark logo, enter a note for the update, and press enter."
  },
  {
    "objectID": "workbooks/001_Setup.html#libraries-and-installing-things",
    "href": "workbooks/001_Setup.html#libraries-and-installing-things",
    "title": "1  Tools and Setup",
    "section": "1.4 Libraries and Installing Things",
    "text": "1.4 Libraries and Installing Things\nOne thing you’ll see all the time in Python, and programming in general, are “import” statements littered about, especially at the top of a program. These import statements grab libraries - packages of code that other people have written, and include it in our program so we can use it. Most of the stuff that we use isn’t part of the core of Python itself, they are things that were written, shared, and reused over and over. Some of the common ones that we’ll spend time with right away are:\n\n\nPandas - provides the dataframes that hold data.\n\nNumpy - provides an assortment of math-like things, as well as arrays which we’ll use later.\n\nSeaborn - provides graphing and visualization functions.\n\nThere is a near infinite list of other ones that may be useful, we generally want to use these things when they exist (outside of doing something for the purposes of learning about it), as published packages are generally tested, optimized, and maintained, so they’ll normally function better than whatever we can write. Anaconda packages many of the common libraries into one bundle, so for most things we can just add an “import whatever” statement and use it. There are lots of things that Anaconda doesn’t package, so if we need one of those things, we need to install it. This is usually a simple process, but may require some setup and config for your particular machine, especially if you’re on Windows.\nThere are a few ways we can install things, from easiest to most complex:\n\n1.4.0.1 Install via Magic Commands\nWe can write a special command in code that basically sidesteps python and runs a command on your underlying machine. We can add one of these at the head of a program that needs to install stuff, and it will run the installation if it is needed when you run the code. This is useful if you may be running code in different environments, such as running code in VS Code and Google Colab, as it will do the install right up front. Again, there are two ways to install stuff here:\n\n\nInstall using conda. Anaconda has an installer that we can run.\n\n\n!conda install PACKAGENAME\n\nE.g. to install pip - !conda install pip\n\n\nInsall using pip. Pip is the most common python installer, and if you see examples online they will normally use pip. You MAY need to install pip first to use it. I normally use pip\n\n\n!pip install PACKAGENAME\n\n\n\n\n1.4.0.2 Install via Terminal Commands\n\n\n1.4.0.3 Install via Anaconda GUI\n\n\n1.4.0.4 Install via Requirements File\nWe won’t really do this, because it is more for production, but another common way to install needed stuff is to use a requirements file, which is just a text file with a list of needed libraries (and specific versions, if desired). An action can be setup to verifiy that all the requirements are met when testing/executing the code. For example, you could setup a repository on GitHub that ran a set of tests on your code when you check it in, and setup an environment with all the requirements in the process of doing so.\n\n\n1.4.1 Potential Issues\nThere are a few, machine specific things, that can go wrong or weird with this.\n\n1.4.1.1 PATH Setup\nThe most common issue is a need to add something to the PATH. The PATH is roughly something that defines what programs you can run by name - i.e. if you were to open a terminal and type “Excel” and hit enter, MS Excel would probably open. If you type “conda/pip install whatever” and there’s an error that it is an unknown command or similar, this is likely the issue. The solution is generally simple, you need to edit a value in your OS’s configuration. Google “pip/conda add to path [my operating system version]” and there should be a multitude of examples online showing you what to add with screenshots and even recordings.\n\n\n1.4.1.2 Environments\nOne thing to be attentitve to in all this is the python environment. These installs are a per-environment thing, so an easy way to get confsued is to install one in a different environment by accident."
  },
  {
    "objectID": "workbooks/001_Setup.html#setup-tasks",
    "href": "workbooks/001_Setup.html#setup-tasks",
    "title": "1  Tools and Setup",
    "section": "1.5 Setup Tasks",
    "text": "1.5 Setup Tasks\n\n\nInstall pip.\n\nCreate backup environment from the “base” one.\n\nDo some stuff."
  },
  {
    "objectID": "workbooks/002_Describing_One_Variable_sol.html",
    "href": "workbooks/002_Describing_One_Variable_sol.html",
    "title": "2  Stats Basics - Describing One Variable",
    "section": "",
    "text": "The first step on our statistical journey is to look at how we can describe one variable at a time.\nIn short, we want to be able to load in a dataset, manipulate it to get what we care about, and look at the data (starting with one variable) to see what it says. This is a near universal starting point for doing machine learning, it all starts with the data, so gaining some understanding of that data will help us out."
  },
  {
    "objectID": "workbooks/002_Describing_One_Variable_sol.html#storing-data---dataframes",
    "href": "workbooks/002_Describing_One_Variable_sol.html#storing-data---dataframes",
    "title": "2  Stats Basics - Describing One Variable",
    "section": "2.1 Storing Data - Dataframes",
    "text": "2.1 Storing Data - Dataframes\nWe’ll load the Titanic data from last time into a dataframe again. Dataframes are one of our most commonly used data structures (thing that stores a bunch of data in an organized way). We can think of a dataframe as a well formatted spreadsheet:\n\n\nEach column represents one feature (variable) that is part of our data.\n\nEach row represents one instance (example) of whatever we’re looking at.\n\nEach cell is one value.\n\n\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Name\n      Sex\n      Age\n      SibSp\n      Parch\n      Ticket\n      Fare\n      Cabin\n      Embarked\n    \n  \n  \n    \n      0\n      1\n      0\n      3\n      Braund, Mr. Owen Harris\n      male\n      22.0\n      1\n      0\n      A/5 21171\n      7.2500\n      NaN\n      S\n    \n    \n      1\n      2\n      1\n      1\n      Cumings, Mrs. John Bradley (Florence Briggs Th...\n      female\n      38.0\n      1\n      0\n      PC 17599\n      71.2833\n      C85\n      C\n    \n    \n      2\n      3\n      1\n      3\n      Heikkinen, Miss. Laina\n      female\n      26.0\n      0\n      0\n      STON/O2. 3101282\n      7.9250\n      NaN\n      S\n    \n    \n      3\n      4\n      1\n      1\n      Futrelle, Mrs. Jacques Heath (Lily May Peel)\n      female\n      35.0\n      1\n      0\n      113803\n      53.1000\n      C123\n      S\n    \n    \n      4\n      5\n      0\n      3\n      Allen, Mr. William Henry\n      male\n      35.0\n      0\n      0\n      373450\n      8.0500\n      NaN\n      S\n    \n  \n\n\n\n\n\n2.1.1 Slicing Dataframes\nWe can select different parts of a dataframe at a time. Most commonly, we want to get one or more of the columns. We can use the column names to get what we want. There are multiple ways to do this, but we will almost always settle on the last one.\nSuppose we want the column of “Survived” - 0 for Leo, 1 for Kate.\n\n\n0      0\n1      1\n2      1\n3      1\n4      0\n      ..\n886    0\n887    1\n888    0\n889    1\n890    0\nName: Survived, Length: 891, dtype: int64\n\n\n\n\n0      0\n1      1\n2      1\n3      1\n4      0\n      ..\n886    0\n887    1\n888    0\n889    1\n890    0\nName: Survived, Length: 891, dtype: int64\n\n\n\n\n0      0\n1      1\n2      1\n3      1\n4      0\n      ..\n886    0\n887    1\n888    0\n889    1\n890    0\nName: Survived, Length: 891, dtype: int64\n\n\n\n2.1.1.1 Exercise\nChallenge - print multiple columns. Such as Survived and Age!\nYou may need to Google, think about what to Google and try to implement what you find. Try to Speculate why the formatting might be a little different here than for one variable.\n\n\n\n\n\n\n  \n    \n      \n      Survived\n      Age\n    \n  \n  \n    \n      0\n      0\n      22.0\n    \n    \n      1\n      1\n      38.0\n    \n    \n      2\n      1\n      26.0\n    \n    \n      3\n      1\n      35.0\n    \n    \n      4\n      0\n      35.0\n    \n    \n      ...\n      ...\n      ...\n    \n    \n      886\n      0\n      27.0\n    \n    \n      887\n      1\n      19.0\n    \n    \n      888\n      0\n      NaN\n    \n    \n      889\n      1\n      26.0\n    \n    \n      890\n      0\n      32.0\n    \n  \n\n891 rows × 2 columns\n\n\n\n\n\n\n2.1.2 Slicing by Rows\nWe can also select rows from a dataframe. This is generally less important for most of the things that we do. We can select the specific rows we want, or give a condition to filter by. This is effectively the same as using the filter feature in Excel.\n\n\n\n\n\n\n  \n    \n      \n      Survived\n      Age\n    \n  \n  \n    \n      0\n      0\n      22.0\n    \n    \n      1\n      1\n      38.0\n    \n    \n      2\n      1\n      26.0\n    \n    \n      3\n      1\n      35.0\n    \n    \n      4\n      0\n      35.0\n    \n  \n\n\n\n\n\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Name\n      Sex\n      Age\n      SibSp\n      Parch\n      Ticket\n      Fare\n      Cabin\n      Embarked\n    \n  \n  \n    \n      0\n      1\n      0\n      3\n      Braund, Mr. Owen Harris\n      male\n      22.0\n      1\n      0\n      A/5 21171\n      7.2500\n      NaN\n      S\n    \n    \n      4\n      5\n      0\n      3\n      Allen, Mr. William Henry\n      male\n      35.0\n      0\n      0\n      373450\n      8.0500\n      NaN\n      S\n    \n    \n      5\n      6\n      0\n      3\n      Moran, Mr. James\n      male\n      NaN\n      0\n      0\n      330877\n      8.4583\n      NaN\n      Q\n    \n    \n      6\n      7\n      0\n      1\n      McCarthy, Mr. Timothy J\n      male\n      54.0\n      0\n      0\n      17463\n      51.8625\n      E46\n      S\n    \n    \n      7\n      8\n      0\n      3\n      Palsson, Master. Gosta Leonard\n      male\n      2.0\n      3\n      1\n      349909\n      21.0750\n      NaN\n      S\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      884\n      885\n      0\n      3\n      Sutehall, Mr. Henry Jr\n      male\n      25.0\n      0\n      0\n      SOTON/OQ 392076\n      7.0500\n      NaN\n      S\n    \n    \n      885\n      886\n      0\n      3\n      Rice, Mrs. William (Margaret Norton)\n      female\n      39.0\n      0\n      5\n      382652\n      29.1250\n      NaN\n      Q\n    \n    \n      886\n      887\n      0\n      2\n      Montvila, Rev. Juozas\n      male\n      27.0\n      0\n      0\n      211536\n      13.0000\n      NaN\n      S\n    \n    \n      888\n      889\n      0\n      3\n      Johnston, Miss. Catherine Helen \"Carrie\"\n      female\n      NaN\n      1\n      2\n      W./C. 6607\n      23.4500\n      NaN\n      S\n    \n    \n      890\n      891\n      0\n      3\n      Dooley, Mr. Patrick\n      male\n      32.0\n      0\n      0\n      370376\n      7.7500\n      NaN\n      Q\n    \n  \n\n549 rows × 12 columns\n\n\n\nThis can be used to select only the portion of data that we want in a given scenario. For example, if we only wanted Titanic survivors that are in the 18 to 34 age range (pretend we are trying to sell TV ads), we can select that.\n\n\n\n\n\n\n  \n    \n      \n      PassengerId\n      Survived\n      Pclass\n      Age\n      SibSp\n      Parch\n      Fare\n    \n  \n  \n    \n      count\n      135.000000\n      135.0\n      135.000000\n      135.000000\n      135.000000\n      135.000000\n      135.000000\n    \n    \n      mean\n      448.637037\n      1.0\n      2.037037\n      26.048148\n      0.385185\n      0.400000\n      41.502840\n    \n    \n      std\n      250.067502\n      0.0\n      0.832255\n      4.772384\n      0.690935\n      0.764902\n      54.572639\n    \n    \n      min\n      3.000000\n      1.0\n      1.000000\n      18.000000\n      0.000000\n      0.000000\n      0.000000\n    \n    \n      25%\n      257.000000\n      1.0\n      1.000000\n      22.000000\n      0.000000\n      0.000000\n      9.670850\n    \n    \n      50%\n      431.000000\n      1.0\n      2.000000\n      26.000000\n      0.000000\n      0.000000\n      21.000000\n    \n    \n      75%\n      651.000000\n      1.0\n      3.000000\n      30.000000\n      1.000000\n      0.000000\n      55.220850\n    \n    \n      max\n      890.000000\n      1.0\n      3.000000\n      34.000000\n      3.000000\n      3.000000\n      263.000000"
  },
  {
    "objectID": "workbooks/002_Describing_One_Variable_sol.html#types-of-data",
    "href": "workbooks/002_Describing_One_Variable_sol.html#types-of-data",
    "title": "2  Stats Basics - Describing One Variable",
    "section": "2.2 Types of Data",
    "text": "2.2 Types of Data\nWe have several different types of data that we may need to deal with. The most important split is the difference between categorical data and numerical data. This is one thing that we need to be very comfortable with:\n\n\nNumerical Data - typically a measurement, reading, or value that is numerical. E.g. Net worth, age, temperature, belt size, etc…\n\n\nRule of thumb - if you can plot a value on a number line and “do math” to it - e.g. compare greater/lesser, add, divide - then it is probably numerical.\n\n\nCategorical Data - typically a label, descriptor, or group indicator. E.g. hair color, land zoning, car make, type of tree, etc…\n\n\nRule of thumb - if you would “group by” a value, it is normally categorical.\n\n\nUsually determining which data type our data falls into is relatively easy, but there are some scenarios where it isn’t. Most notably, numbers are often used to denote group types, so they sometimes act as categorical values. For example, if we were to group people by their nationality and label those groups 1, 2, 3, etc… that is a use of a numerical variable as a categorical value. We will need to do things like this later on.\n\n2.2.0.1 Python Data Types\nEvery programming language has a few built in data types that it naturally supports. Some important and common ones are:\n\n\nString - text.\n\nInteger - number without decimals.\n\nFloat - number with decimals.\n\nBool - true/false.\n\nThe “type()” function will show the type of any object.\nNote: Python is what we called a weakly typed language, which basically means that an individual varaible can take on any type of value (this is in comparison to a strongly typed language, where if you create an integer varaible, it can only be an integer). This has the advantage of making things easy to do, as there’s no restrictions on what you can do with a variable; however, it can also lead to confusion as it makes it easier to make an error such as putting a text value in a varaible when you are expecting a number. Using clear variable names is the most simple way to protect against this.\n\n\n<class 'str'>\n<class 'int'>\n<class 'float'>\n<class 'bool'>"
  },
  {
    "objectID": "workbooks/002_Describing_One_Variable_sol.html#counts-of-categorical-variables",
    "href": "workbooks/002_Describing_One_Variable_sol.html#counts-of-categorical-variables",
    "title": "2  Stats Basics - Describing One Variable",
    "section": "2.3 Counts of Categorical Variables",
    "text": "2.3 Counts of Categorical Variables\nWhen dealing with categorical variables the most important thing that we can know is how many times each value occurs.\n\n\n3    491\n1    216\n2    184\nName: Pclass, dtype: int64\n\n\n\n\n0\n\n\n\n2.3.0.1 Countplots\nWe can also use a very simple visualization to see the counts broken down. Each tab holds the same countplot, the difference in the second one is that we added an argument for “hue”, which is a common argument in seaborn graphs that separates the data by whatever you put there. Here we gave it the “Survived” variable, so each of the bars is split into survived/died subsets.\n\nCountplotCountplot - Split\n\n\n\n\n<AxesSubplot:xlabel='Pclass', ylabel='count'>\nA countplot\n\n\n\n\n\n\n\n\n\n<AxesSubplot:xlabel='Pclass', ylabel='count'>\nA countplot"
  },
  {
    "objectID": "workbooks/002_Describing_One_Variable_sol.html#distribution-of-numerical-variables",
    "href": "workbooks/002_Describing_One_Variable_sol.html#distribution-of-numerical-variables",
    "title": "2  Stats Basics - Describing One Variable",
    "section": "2.4 Distribution of Numerical Variables",
    "text": "2.4 Distribution of Numerical Variables\nProbably the most critical thing we can know about a numerical variable is its distribution - or how many times different values occur.\nWe can also get these statistics individually. This time I added print statements, this just makes the program print more than one output, if all the print statements are left our we’d only get the last one.\nThis is one place where we can easily see multiple ways to do things, which is very common in programming. Specifically, we have several sets of functions that do basic math. Here we have an example of probably the two most common ones:\n\n\nPandas - the library that provides dataframes for us.\n\nNumpy - this library has a bunch of useful math-y stuff.\n\nNote the difference in how the code is structured for each one, this is due to where these functions come from. The pandas ones are called by stating DATFRAME.FUNCTION() - this is because the functions “are part of” pandas, so we can tell it to basically “find the mean function for this object (the df)” and the program will look inside of Pandas for that thing. This works because the dataframe has its own mean/std/count function built into it. The numpy ones are more generic, and we call them by saying LIBRARY.FUNCTION(DATA). This is because these are not part of the dataframe, we are calling a generic function and feeding it our data. We don’t need a dataframe to use this, we can feed it (almost) any data - lists, arrays, series, etc… since it is not part of an object. This basic split is something that is pretty universal in most programming languages, it feels arbitrary at first but it does become natural over time.\nNote: the median below and the 50% above are the same. The median is the value “in the middle” - half of the values are higher, half lower.\n\n2.4.0.1 Examples of Basic Stats Functions.\n\nDescribePandasNumpy\n\n\n\n\ncount    891.000000\nmean      32.204208\nstd       49.693429\nmin        0.000000\n25%        7.910400\n50%       14.454200\n75%       31.000000\nmax      512.329200\nName: Fare, dtype: float64\n\n\n\n\n\n\nMean:  32.2042079685746\nMedian:  14.4542\nMin:  0.0\nMax:  512.3292\nCount:  891\nVariance:  2469.436845743117\nStd. Dev:  49.693428597180905\n\n\n\n\n\n\nMean:  32.2042079685746\nMedian:  14.4542\nMin:  0.0\nMax:  512.3292\nVariance:  2466.6653116850434\nStd. Dev:  49.66553444477411"
  },
  {
    "objectID": "workbooks/002_Describing_One_Variable_sol.html#distributions",
    "href": "workbooks/002_Describing_One_Variable_sol.html#distributions",
    "title": "2  Stats Basics - Describing One Variable",
    "section": "2.5 Distributions",
    "text": "2.5 Distributions\nWhen looking at a variable, calculating things like the mean or median is useful, but very incomplete. We probably want to know more about the values and how frequently they occur - something called the distribution.\nDistributions are one of the fundamental concepts of statistics, one that well use constantly. We’ll dig into them a bunch more over the next few sessions.\n\n2.5.1 Types of Distributions\nDistributions commonly follow patterns, and we can use these paterns to help us build an understanding of our own data.\nWe will look more at specific distributions in more detail soon, for now, we can think of distributions as describing the shape of the data, or how it is distributed over the range.\n\n2.5.1.1 Histograms\nThe histogram is the most common tool used to examine a distribution. A histogram is a specialized type of bar chart that is always structured in the same way:\n\n\nThe X axis is the variable we are looking at.\n\nThe Y axis is a count of how many times that value occurs.\n\nHistograms will be one of our most frequently used visualizations - luckily they are pretty simple.\n\n\n2.5.1.2 Seaborn and Graphing\nThere are many, many packages that allow us to draw charts and visualizations in Python. The main one we’ll focus on is called Seaborn. Seaborn is a package of graphing and charting tools that makes it relatively easy to make pretty charts.\nSeaborn is not the only choice, but it is common, pretty, and easy, so we’ll stick with it for the most part.\nThere are several types of graphs that we can look at to picture the distribution of our data.\n\nHistogramPDFCDFHist w/ PDF\n\n\n\n\n<AxesSubplot:xlabel='Age', ylabel='Count'>\n\n\n\n\n\n\n\n\n\n<AxesSubplot:xlabel='Age', ylabel='Density'>\n\n\n\n\n\n\n\n\n\n<AxesSubplot:xlabel='Age', ylabel='Density'>\n\n\n\n\n\n\n\n\n\n<AxesSubplot:xlabel='Age', ylabel='Count'>\n\n\n\n\n\n\n\n\n\n\n\n2.5.2 Seaborn, Matplotlib, and Graphing\nWe can do something similar with the underlying functionality of Seaborn - matplotlib and pyplot. Matplotlib is the “granddaddy” of graphing in Python, and the entire Seaborn package is built on top of it. The mpl stuff is generally less fancy looking and more confusing to use, but we do need to be at least a bit aware of it.\nWhy is this important?\n\n\nSometimes we need the “original” matplotlib stuff to do things, even when making Seaborn charts.\n\nIf we are looking for examples/explainations online, there is a high probability that we see some mpl stuff in that code.\n\nOne of the key things that makes programming a usefull thing is the ability to have functionality that is modular and can be extended (build better things on top of existing code). This is one of the first places where we start to deal with that. In the example below, we should be able to see that code for a histogram, read it, understand the goal, and replace it with a Seaborn histogram shoudl we desire.\n\n\n\n<AxesSubplot:ylabel='Frequency'>"
  },
  {
    "objectID": "workbooks/002_Describing_One_Variable_sol.html#outliers",
    "href": "workbooks/002_Describing_One_Variable_sol.html#outliers",
    "title": "2  Stats Basics - Describing One Variable",
    "section": "2.6 Outliers",
    "text": "2.6 Outliers\nOutliers are values that are “far outside the norm”, or basically values that fall to the extreme left of extreme right of our distribution.\n\n2.6.1 Dealing with Outliers\nDealing with outliers is always a matter of judgement - sometimes an outlier is real and relevant, so we want to keep it in; sometimes an outlier is an error or misleading, so we want to remove it.\nAs a rule of thumb, we can think of what to do outliers like this:\n\n\nIf the outlier is going to help inform our model, and will help create more accurate predictions, we want to leave it in.\n\nIf the outlier is going to skew our results, and will make predictions less accurate, we want to remove it.\n\nIn practice, most outliers are filtered out. Knowing that Elon Musk has 300 billion dollars will rarely be helpful in building a model to predict the net worth of people. Usually this is the case, outliers are very rare, and don’t really help in predicting a “normal” value.\nWe have ways to automatically (-ish) remove outliers that we’ll look at later on in the course. The most simple way to remove outliers is to just create a filter that removes every value that is greater or less than a cutoff. Our histograms can often give us a good idea of what that cutoff should be as we can see it visually on the graph.\n\n\n<AxesSubplot:xlabel='Fare', ylabel='Count'>"
  },
  {
    "objectID": "workbooks/002_Describing_One_Variable_sol.html#where-are-we-now",
    "href": "workbooks/002_Describing_One_Variable_sol.html#where-are-we-now",
    "title": "2  Stats Basics - Describing One Variable",
    "section": "2.7 Where Are We Now?",
    "text": "2.7 Where Are We Now?\nAt this point, we are hopefully becoming moderately comfortable with:\n\n\nOpening, running, and editing notebook files.\n\nLoading data into a dataframe and starting to manipulate it.\n\nStarting to use calculations and visualizations to describe data."
  }
]